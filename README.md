# ğŸš€ Student EDA & Machine Learning Practice

This repository contains my structured learning journey in Exploratory Data Analysis (EDA) and foundational Machine Learning concepts.

I have documented my daily practice while strengthening my understanding of data preprocessing, statistical concepts, visualization techniques, and regression modeling.

---

## ğŸ“š Learning Progress

### ğŸ“… Day 1 â€“ Python & Basics
- Basic data handling
- Introduction to notebooks

### ğŸ“… Day 2 â€“ Pandas Practice
- DataFrames
- Data manipulation
- Filtering & indexing

### ğŸ“… Day 3 â€“ Data Cleaning
- Handling missing values
- Outlier treatment
- Data transformation

### ğŸ“… Day 4 â€“ Customer Dataset Analysis
- Exploratory Data Analysis
- Basic visualizations

### ğŸ“… Day 5 â€“ Feature Scaling
- Standardization
- Normalization
- Scaling techniques

### ğŸ“… Day 6 â€“ Statistics
- Mean, Median, Mode
- Variance & Standard Deviation

### ğŸ“… Day 7 â€“ Z-Score & Outlier Detection
- Z-score calculation
- Identifying extreme values

### ğŸ“… Day 8 â€“ Titanic Dataset EDA
- Data visualization
- Feature relationships
- Survival analysis

### ğŸ“… Day 9 â€“ Linear Regression
- Regression modeling
- Model fitting
- Basic prediction
### day10
ğŸ“Š Multiple Linear Regression

Multiple Linear Regression is a supervised machine learning algorithm used to predict a continuous value using two or more independent variables.

ğŸ”¹ Model Equation
ğ‘Œ
=
ğ›½
0
+
ğ›½
1
ğ‘‹
1
+
ğ›½
2
ğ‘‹
2
+
.
.
.
+
ğ›½
ğ‘›
ğ‘‹
ğ‘›
Y=Î²
0
	â€‹

+Î²
1
	â€‹

X
1
	â€‹

+Î²
2
	â€‹

X
2
	â€‹

+...+Î²
n
	â€‹

X
n
	â€‹

ğŸ”¹ Key Points

Used for regression problems

Assumes linear relationship

Minimizes error using Least Squares

Evaluated using RÂ², MAE, MSE, RMSE

ğŸ”¹ Example Use Cases

House price prediction

Power consumption prediction

Analytical power/delay modeling

### day 11
ğŸ” Logistic Regression

Logistic Regression is a supervised classification algorithm used to predict categorical outcomes (Binary or Multi-class).

ğŸ”¹ Sigmoid Function
ğœ
(
ğ‘§
)
=
1
1
+
ğ‘’
âˆ’
ğ‘§
Ïƒ(z)=
1+e
âˆ’z
1
	â€‹

ğŸ”¹ Key Points

Used for classification problems

Outputs probability (0 to 1)

Uses Log Loss

Evaluated using Accuracy, Precision, Recall, F1-Score

ğŸ”¹ Types

Binary Logistic Regression

Multinomial Logistic Regression

Ordinal Logistic Regression

ğŸ”¹ Example Use Cases

Spam detection

Disease prediction

Customer churn prediction

### day 12
ğŸ“Œ K-Nearest Neighbors (KNN)

K-Nearest Neighbors (KNN) is a supervised machine learning algorithm used for both classification and regression tasks.
It predicts the output based on the K closest data points in the dataset.

ğŸ”¹ How It Works

Choose the value of K (number of neighbors).

Calculate the distance between the new point and all training points.

Select the K nearest neighbors.

For classification â†’ Majority voting

For regression â†’ Average of neighbors

ğŸ”¹ Key Features

Non-parametric (no assumption about data distribution)

Lazy learning (no explicit training phase)

Distance-based algorithm (Euclidean commonly used)

Sensitive to feature scaling

ğŸ”¹ Common Distance Formula (Euclidean)
ğ‘‘
=
(
ğ‘¥
1
âˆ’
ğ‘¥
2
)
2
+
(
ğ‘¦
1
âˆ’
ğ‘¦
2
)
2
d=
(x
1
	â€‹

âˆ’x
2
	â€‹

)
2
+(y
1
	â€‹

âˆ’y
2
	â€‹

)
2
	â€‹

ğŸ”¹ Advantages

Simple and easy to understand

Works well for small datasets

Effective for non-linear problems

ğŸ”¹ Disadvantages

Slow for large datasets

Sensitive to noise

Requires feature scaling

Affected by curse of dimensionality

ğŸ”¹ Use Cases

Recommendation systems

Pattern recognition

Credit scoring

Medical diagnosis

---

## ğŸ›  Tools & Technologies Used

- Python
- Pandas
- NumPy
- Matplotlib
- Seaborn
- Scikit-Learn
- Jupyter Notebook

---

## ğŸ¯ Objective

The goal of this repository is to:

- Build strong fundamentals in Data Science
- Practice real datasets
- Improve analytical thinking
- Prepare for advanced Machine Learning projects

---

## ğŸ“ˆ Future Plans

- Model evaluation techniques
- Classification algorithms
- Feature engineering
- Deployment projects

---

â­ This repository reflects my consistent learning journey in Machine Learning and Data Science.
